2023-03-04 15:56:34,085 maskrcnn_benchmark INFO: Using 1 GPUs
2023-03-04 15:56:34,085 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_rel_ovi6.yaml', distributed=False, local_rank=0, loss_option='CROSS_ENTROPY_LOSS', num_experts=1, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'False', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'False', 'MODEL.ROI_RELATION_HEAD.USE_RELATION_AWARE_GATING', 'False', 'MODEL.ROI_RELATION_HEAD.USE_PER_CLASS_CONTEXT_AWARE', 'False'], skip_test=False)
2023-03-04 15:56:34,085 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2023-03-04 15:56:36,029 maskrcnn_benchmark INFO: 
PyTorch version: 1.6.0+cu101
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 18.04.3 LTS
GCC version: (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0
CMake version: version 3.10.2

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 10.1.243
GPU models and configuration: GPU 0: Tesla V100-SXM2-32GB
Nvidia driver version: 418.67
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.17.3
[pip3] torch==1.6.0+cu101
[pip3] torch-tb-profiler==0.2.1
[pip3] torchaudio==0.8.1
[pip3] torchfile==0.1.0
[pip3] torchvision==0.7.0+cu101
[conda] Could not collect
        Pillow (6.2.1)
2023-03-04 15:56:36,030 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_rel_ovi6.yaml
2023-03-04 15:56:36,030 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  # CAME
  REL_CLASS_NUM_LST: [ ]
  OBJ_CLASS_NUM_LST: [ ]
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 602                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 0             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_BGFG_RATIO: 3
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 31                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    ## CAME, 2022
    NUM_EXPERTS: 2
    USE_RELATION_AWARE_GATING: False
    USE_PER_CLASS_CONTEXT_AWARE: False
    PER_CLASS_ALPHA: 1.0
    LOSS_OPTION: "CAME_LOSS"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1 # fro fgpl 0.3
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048
DATASETS:
  TRAIN: ("openimage_v6_train",)
  VAL: ("openimage_v6_val",)
  TEST: ("openimage_v6_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5
  CUSTUM_EVAL: False       # eval SGDet model on custum images, output a json
  CUSTUM_PATH: '.'         # the folder that contains the custum images, only jpg files are allowed

2023-03-04 15:56:36,036 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  GQA_200_TEST: ()
  GQA_200_TRAIN: ()
  GQA_200_VAL: ()
  LOAD_PRECOMPUTE_DETECTION_BOX: False
  TEST: ('openimage_v6_test',)
  TRAIN: ('openimage_v6_train',)
  VAL: ('openimage_v6_val',)
  VG_TEST: ()
  VG_TRAIN: ()
  VG_VAL: ()
DETECTED_SGG_DIR: .
DTYPE: float16
GLOBAL_SETTING:
  BASIC_ENCODER: Hybrid-Attention
  CHOOSE_BEST_MODEL_BY_METRIC: _mean_recall
  DATASET_CHOICE: VG
  GCL_SETTING:
    GROUP_SPLIT_MODE: divide4
    KNOWLEDGE_LOSS_COEFFICIENT: 1.0
    KNOWLEDGE_TRANSFER_MODE: KL_logit_TopDown
    NO_RELATION_PENALTY: 0.1
    NO_RELATION_RESTRAIN: True
    ZERO_LABEL_PADDING_MODE: rand_insert
  PRINT_INTERVAL: 100
  RELATION_PREDICTOR: TransLike_GCL
  USE_BIAS: True
GLOVE_DIR: datasets/vg/glove
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  OBJ_CLASS_NUM_LST: []
  PRETRAINED_DETECTOR_CKPT: datasets/vg/detector_model/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  REL_CLASS_NUM_LST: []
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 0
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    GQA_200_NUM_CLASSES: 201
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 602
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
    VG_NUM_CLASSES: 151
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: none
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    DATA_RESAMPLING: False
    DATA_RESAMPLING_METHOD: bilvl
    DATA_RESAMPLING_PARAM:
      INSTANCE_DROP_RATE: 0.4
      REPEAT_DICT_DIR: 
      REPEAT_FACTOR: 0.012
    EMBED_DIM: 200
    EXPERT_VOTING: False
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    GQA_200_NUM_CLASSES: 101
    LABEL_SMOOTHING_LOSS: False
    LONGTAIL_PART_DICT: ['None', 'h', 't', 't', 'b', 'b', 'h', 'b', 'h', 'b', 'b', 'b', 't', 'b', 'b', 't', 'b', 't', 't', 'b', 'h', 'h', 'h', 'h', 'b', 'b', 't', 't', 't', 'h', 'h', 'h', 't', 'b', 't', 'b', 't', 't', 'h', 't', 'h', 'h', 't', 'h', 'b', 't', 'b', 'b', 'h', 'h', 'h']
    LOSS_OPTION: CROSS_ENTROPY_LOSS
    NUM_CLASSES: 31
    NUM_EXPERTS: 1
    NUM_SAMPLE_PER_GT_REL: 4
    PER_CLASS_ALPHA: 1.0
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: CausalAnalysisPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    RELATION_SAMPLING: False
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REPEAT_FACTOR: 0.02
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: False
    USE_GT_OBJECT_LABEL: False
    USE_PER_CLASS_CONTEXT_AWARE: False
    USE_RELATION_AWARE_GATING: False
    VG_NUM_CLASSES: 51
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: ./output/relation_baseline
PATHS_CATALOG: /lintianlin_group_v100/lgzhou/scene_graph_generation/came/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /lintianlin_group_v100/lgzhou/scene_graph_generation/came/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 16
  MAX_ITER: 40000
  MOMENTUM: 0.9
  PRE_VAL: False
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  CUSTUM_EVAL: False
  CUSTUM_PATH: .
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 8
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2023-03-04 15:56:36,040 maskrcnn_benchmark INFO: Saving config into: ./output/relation_baseline/config.yml
2023-03-04 15:56:36,073 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-04 15:56:36,073 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2023-03-04 15:57:01,254 maskrcnn_benchmark.data.build INFO: finish
2023-03-04 15:57:01,255 maskrcnn_benchmark.data.build INFO: Save data statistics to: ./output/relation_baseline/openimage_v6_train_statistics.cache
2023-03-04 15:57:01,255 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-04 15:57:01,863 maskrcnn_benchmark INFO: #################### prepare training ####################
2023-03-04 15:57:06,495 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-04 15:57:06,495 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2023-03-04 15:57:06,496 maskrcnn_benchmark.data.build INFO: Loading data statistics from: ./output/relation_baseline/openimage_v6_train_statistics.cache
2023-03-04 15:57:06,496 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-04 15:57:30,844 maskrcnn_benchmark.data.build INFO: finish
2023-03-04 15:57:30,844 maskrcnn_benchmark.data.build INFO: Save data statistics to: ./output/relation_baseline/openimage_v6_train_statistics.cache
2023-03-04 15:57:30,844 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-04 15:57:40,387 maskrcnn_benchmark INFO: #################### end model construction ####################
2023-03-04 15:57:41,160 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2023-03-04 15:57:41,167 maskrcnn_benchmark INFO: #################### end distributed ####################
2023-03-04 15:57:41,171 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from datasets/vg/detector_model/pretrained_faster_rcnn/model_final.pth
2023-03-04 15:58:27,688 maskrcnn_benchmark INFO: Using 1 GPUs
2023-03-04 15:58:27,688 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_rel_ovi6.yaml', distributed=False, local_rank=0, loss_option='CROSS_ENTROPY_LOSS', num_experts=1, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'False', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'False', 'MODEL.ROI_RELATION_HEAD.USE_RELATION_AWARE_GATING', 'False', 'MODEL.ROI_RELATION_HEAD.USE_PER_CLASS_CONTEXT_AWARE', 'False'], skip_test=False)
2023-03-04 15:58:27,688 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2023-03-04 15:58:29,672 maskrcnn_benchmark INFO: 
PyTorch version: 1.6.0+cu101
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 18.04.3 LTS
GCC version: (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0
CMake version: version 3.10.2

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 10.1.243
GPU models and configuration: GPU 0: Tesla V100-SXM2-32GB
Nvidia driver version: 418.67
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.17.3
[pip3] torch==1.6.0+cu101
[pip3] torch-tb-profiler==0.2.1
[pip3] torchaudio==0.8.1
[pip3] torchfile==0.1.0
[pip3] torchvision==0.7.0+cu101
[conda] Could not collect
        Pillow (6.2.1)
2023-03-04 15:58:29,673 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_rel_ovi6.yaml
2023-03-04 15:58:29,674 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  # CAME
  REL_CLASS_NUM_LST: [ ]
  OBJ_CLASS_NUM_LST: [ ]
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 602                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 0             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_BGFG_RATIO: 3
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 31                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    ## CAME, 2022
    NUM_EXPERTS: 2
    USE_RELATION_AWARE_GATING: False
    USE_PER_CLASS_CONTEXT_AWARE: False
    PER_CLASS_ALPHA: 1.0
    LOSS_OPTION: "CAME_LOSS"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1 # fro fgpl 0.3
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048
DATASETS:
  TRAIN: ("openimage_v6_train",)
  VAL: ("openimage_v6_val",)
  TEST: ("openimage_v6_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5
  CUSTUM_EVAL: False       # eval SGDet model on custum images, output a json
  CUSTUM_PATH: '.'         # the folder that contains the custum images, only jpg files are allowed

2023-03-04 15:58:29,678 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  GQA_200_TEST: ()
  GQA_200_TRAIN: ()
  GQA_200_VAL: ()
  LOAD_PRECOMPUTE_DETECTION_BOX: False
  TEST: ('openimage_v6_test',)
  TRAIN: ('openimage_v6_train',)
  VAL: ('openimage_v6_val',)
  VG_TEST: ()
  VG_TRAIN: ()
  VG_VAL: ()
DETECTED_SGG_DIR: .
DTYPE: float16
GLOBAL_SETTING:
  BASIC_ENCODER: Hybrid-Attention
  CHOOSE_BEST_MODEL_BY_METRIC: _mean_recall
  DATASET_CHOICE: VG
  GCL_SETTING:
    GROUP_SPLIT_MODE: divide4
    KNOWLEDGE_LOSS_COEFFICIENT: 1.0
    KNOWLEDGE_TRANSFER_MODE: KL_logit_TopDown
    NO_RELATION_PENALTY: 0.1
    NO_RELATION_RESTRAIN: True
    ZERO_LABEL_PADDING_MODE: rand_insert
  PRINT_INTERVAL: 100
  RELATION_PREDICTOR: TransLike_GCL
  USE_BIAS: True
GLOVE_DIR: datasets/vg/glove
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  OBJ_CLASS_NUM_LST: []
  PRETRAINED_DETECTOR_CKPT: datasets/vg/detector_model/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  REL_CLASS_NUM_LST: []
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 0
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    GQA_200_NUM_CLASSES: 201
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 602
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
    VG_NUM_CLASSES: 151
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: none
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    DATA_RESAMPLING: False
    DATA_RESAMPLING_METHOD: bilvl
    DATA_RESAMPLING_PARAM:
      INSTANCE_DROP_RATE: 0.4
      REPEAT_DICT_DIR: 
      REPEAT_FACTOR: 0.012
    EMBED_DIM: 200
    EXPERT_VOTING: False
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    GQA_200_NUM_CLASSES: 101
    LABEL_SMOOTHING_LOSS: False
    LONGTAIL_PART_DICT: ['None', 'h', 't', 't', 'b', 'b', 'h', 'b', 'h', 'b', 'b', 'b', 't', 'b', 'b', 't', 'b', 't', 't', 'b', 'h', 'h', 'h', 'h', 'b', 'b', 't', 't', 't', 'h', 'h', 'h', 't', 'b', 't', 'b', 't', 't', 'h', 't', 'h', 'h', 't', 'h', 'b', 't', 'b', 'b', 'h', 'h', 'h']
    LOSS_OPTION: CROSS_ENTROPY_LOSS
    NUM_CLASSES: 31
    NUM_EXPERTS: 1
    NUM_SAMPLE_PER_GT_REL: 4
    PER_CLASS_ALPHA: 1.0
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: CausalAnalysisPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    RELATION_SAMPLING: False
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REPEAT_FACTOR: 0.02
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: False
    USE_GT_OBJECT_LABEL: False
    USE_PER_CLASS_CONTEXT_AWARE: False
    USE_RELATION_AWARE_GATING: False
    VG_NUM_CLASSES: 51
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: ./output/relation_baseline
PATHS_CATALOG: /lintianlin_group_v100/lgzhou/scene_graph_generation/came/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /lintianlin_group_v100/lgzhou/scene_graph_generation/came/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 16
  MAX_ITER: 40000
  MOMENTUM: 0.9
  PRE_VAL: False
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  CUSTUM_EVAL: False
  CUSTUM_PATH: .
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 8
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2023-03-04 15:58:29,682 maskrcnn_benchmark INFO: Saving config into: ./output/relation_baseline/config.yml
2023-03-04 15:58:29,714 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-04 15:58:29,715 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2023-03-04 15:58:29,716 maskrcnn_benchmark.data.build INFO: Loading data statistics from: ./output/relation_baseline/openimage_v6_train_statistics.cache
2023-03-04 15:58:29,716 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-04 15:58:55,958 maskrcnn_benchmark.data.build INFO: finish
2023-03-04 15:58:55,958 maskrcnn_benchmark.data.build INFO: Save data statistics to: ./output/relation_baseline/openimage_v6_train_statistics.cache
2023-03-04 15:58:55,958 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-04 15:58:56,620 maskrcnn_benchmark INFO: #################### prepare training ####################
2023-03-04 15:59:01,254 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-04 15:59:01,254 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2023-03-04 15:59:01,255 maskrcnn_benchmark.data.build INFO: Loading data statistics from: ./output/relation_baseline/openimage_v6_train_statistics.cache
2023-03-04 15:59:01,255 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-04 15:59:26,573 maskrcnn_benchmark.data.build INFO: finish
2023-03-04 15:59:26,574 maskrcnn_benchmark.data.build INFO: Save data statistics to: ./output/relation_baseline/openimage_v6_train_statistics.cache
2023-03-04 15:59:26,574 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-04 15:59:35,986 maskrcnn_benchmark INFO: #################### end model construction ####################
2023-03-04 15:59:36,771 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2023-03-04 15:59:36,779 maskrcnn_benchmark INFO: #################### end distributed ####################
2023-03-04 15:59:36,782 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from datasets/vg/detector_model/pretrained_faster_rcnn/model_final.pth
2023-03-05 05:53:40,149 maskrcnn_benchmark INFO: Using 1 GPUs
2023-03-05 05:53:40,149 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_rel_ovi6.yaml', distributed=False, local_rank=0, loss_option='CROSS_ENTROPY_LOSS', num_experts=1, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'False', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'False', 'MODEL.ROI_RELATION_HEAD.USE_RELATION_AWARE_GATING', 'False', 'MODEL.ROI_RELATION_HEAD.USE_PER_CLASS_CONTEXT_AWARE', 'False'], skip_test=False)
2023-03-05 05:53:40,149 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2023-03-05 05:53:42,027 maskrcnn_benchmark INFO: 
PyTorch version: 1.6.0+cu101
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 18.04.3 LTS
GCC version: (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0
CMake version: version 3.10.2

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 10.1.243
GPU models and configuration: GPU 0: Tesla V100-SXM2-32GB
Nvidia driver version: 418.67
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.17.3
[pip3] torch==1.6.0+cu101
[pip3] torch-tb-profiler==0.2.1
[pip3] torchaudio==0.8.1
[pip3] torchfile==0.1.0
[pip3] torchvision==0.7.0+cu101
[conda] Could not collect
        Pillow (6.2.1)
2023-03-05 05:53:42,028 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_rel_ovi6.yaml
2023-03-05 05:53:42,028 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  # CAME
  REL_CLASS_NUM_LST: [ ]
  OBJ_CLASS_NUM_LST: [ ]
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 602                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 0             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_BGFG_RATIO: 3
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 31                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    ## CAME, 2022
    NUM_EXPERTS: 2
    USE_RELATION_AWARE_GATING: False
    USE_PER_CLASS_CONTEXT_AWARE: False
    PER_CLASS_ALPHA: 1.0
    LOSS_OPTION: "CAME_LOSS"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1 # fro fgpl 0.3
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048
DATASETS:
  TRAIN: ("openimage_v6_train",)
  VAL: ("openimage_v6_val",)
  TEST: ("openimage_v6_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5
  CUSTUM_EVAL: False       # eval SGDet model on custum images, output a json
  CUSTUM_PATH: '.'         # the folder that contains the custum images, only jpg files are allowed

2023-03-05 05:53:42,033 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  GQA_200_TEST: ()
  GQA_200_TRAIN: ()
  GQA_200_VAL: ()
  LOAD_PRECOMPUTE_DETECTION_BOX: False
  TEST: ('openimage_v6_test',)
  TRAIN: ('openimage_v6_train',)
  VAL: ('openimage_v6_val',)
  VG_TEST: ()
  VG_TRAIN: ()
  VG_VAL: ()
DETECTED_SGG_DIR: .
DTYPE: float16
GLOBAL_SETTING:
  BASIC_ENCODER: Hybrid-Attention
  CHOOSE_BEST_MODEL_BY_METRIC: _mean_recall
  DATASET_CHOICE: VG
  GCL_SETTING:
    GROUP_SPLIT_MODE: divide4
    KNOWLEDGE_LOSS_COEFFICIENT: 1.0
    KNOWLEDGE_TRANSFER_MODE: KL_logit_TopDown
    NO_RELATION_PENALTY: 0.1
    NO_RELATION_RESTRAIN: True
    ZERO_LABEL_PADDING_MODE: rand_insert
  PRINT_INTERVAL: 100
  RELATION_PREDICTOR: TransLike_GCL
  USE_BIAS: True
GLOVE_DIR: datasets/vg/glove
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  OBJ_CLASS_NUM_LST: []
  PRETRAINED_DETECTOR_CKPT: datasets/vg/detector_model/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  REL_CLASS_NUM_LST: []
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 0
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    GQA_200_NUM_CLASSES: 201
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 602
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
    VG_NUM_CLASSES: 151
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: none
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    DATA_RESAMPLING: False
    DATA_RESAMPLING_METHOD: bilvl
    DATA_RESAMPLING_PARAM:
      INSTANCE_DROP_RATE: 0.4
      REPEAT_DICT_DIR: 
      REPEAT_FACTOR: 0.012
    EMBED_DIM: 200
    EXPERT_VOTING: False
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    GQA_200_NUM_CLASSES: 101
    LABEL_SMOOTHING_LOSS: False
    LONGTAIL_PART_DICT: ['None', 'h', 't', 't', 'b', 'b', 'h', 'b', 'h', 'b', 'b', 'b', 't', 'b', 'b', 't', 'b', 't', 't', 'b', 'h', 'h', 'h', 'h', 'b', 'b', 't', 't', 't', 'h', 'h', 'h', 't', 'b', 't', 'b', 't', 't', 'h', 't', 'h', 'h', 't', 'h', 'b', 't', 'b', 'b', 'h', 'h', 'h']
    LOSS_OPTION: CROSS_ENTROPY_LOSS
    NUM_CLASSES: 31
    NUM_EXPERTS: 1
    NUM_SAMPLE_PER_GT_REL: 4
    PER_CLASS_ALPHA: 1.0
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: CausalAnalysisPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    RELATION_SAMPLING: False
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REPEAT_FACTOR: 0.02
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: False
    USE_GT_OBJECT_LABEL: False
    USE_PER_CLASS_CONTEXT_AWARE: False
    USE_RELATION_AWARE_GATING: False
    VG_NUM_CLASSES: 51
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: ./output/relation_baseline
PATHS_CATALOG: /lintianlin_group_v100/lgzhou/scene_graph_generation/came/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /lintianlin_group_v100/lgzhou/scene_graph_generation/came/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 16
  MAX_ITER: 40000
  MOMENTUM: 0.9
  PRE_VAL: False
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  CUSTUM_EVAL: False
  CUSTUM_PATH: .
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 8
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2023-03-05 05:53:42,037 maskrcnn_benchmark INFO: Saving config into: ./output/relation_baseline/config.yml
2023-03-05 05:53:42,074 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-05 05:53:42,074 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2023-03-05 05:53:42,075 maskrcnn_benchmark.data.build INFO: Loading data statistics from: ./output/relation_baseline/openimage_v6_train_statistics.cache
2023-03-05 05:53:42,075 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-05 05:54:08,816 maskrcnn_benchmark.data.build INFO: finish
2023-03-05 05:54:08,816 maskrcnn_benchmark.data.build INFO: Save data statistics to: ./output/relation_baseline/openimage_v6_train_statistics.cache
2023-03-05 05:54:08,816 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-05 05:54:09,427 maskrcnn_benchmark INFO: #################### prepare training ####################
2023-03-05 05:54:14,012 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-05 05:54:14,012 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2023-03-05 05:54:14,013 maskrcnn_benchmark.data.build INFO: Loading data statistics from: ./output/relation_baseline/openimage_v6_train_statistics.cache
2023-03-05 05:54:14,014 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-05 05:54:39,594 maskrcnn_benchmark.data.build INFO: finish
2023-03-05 05:54:39,594 maskrcnn_benchmark.data.build INFO: Save data statistics to: ./output/relation_baseline/openimage_v6_train_statistics.cache
2023-03-05 05:54:39,594 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-05 05:54:49,031 maskrcnn_benchmark INFO: #################### end model construction ####################
2023-03-05 05:54:50,050 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2023-03-05 05:54:50,056 maskrcnn_benchmark INFO: #################### end distributed ####################
2023-03-05 05:54:50,059 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from datasets/vg/detector_model/pretrained_faster_rcnn/model_final.pth
2023-03-05 05:55:27,548 maskrcnn_benchmark INFO: Using 1 GPUs
2023-03-05 05:55:27,548 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_rel_ovi6.yaml', distributed=False, local_rank=0, loss_option='CROSS_ENTROPY_LOSS', num_experts=1, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'False', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'False', 'MODEL.ROI_RELATION_HEAD.USE_RELATION_AWARE_GATING', 'False', 'MODEL.ROI_RELATION_HEAD.USE_PER_CLASS_CONTEXT_AWARE', 'False'], skip_test=False)
2023-03-05 05:55:27,548 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2023-03-05 05:55:29,557 maskrcnn_benchmark INFO: 
PyTorch version: 1.6.0+cu101
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 18.04.3 LTS
GCC version: (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0
CMake version: version 3.10.2

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 10.1.243
GPU models and configuration: GPU 0: Tesla V100-SXM2-32GB
Nvidia driver version: 418.67
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.17.3
[pip3] torch==1.6.0+cu101
[pip3] torch-tb-profiler==0.2.1
[pip3] torchaudio==0.8.1
[pip3] torchfile==0.1.0
[pip3] torchvision==0.7.0+cu101
[conda] Could not collect
        Pillow (6.2.1)
2023-03-05 05:55:29,558 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_rel_ovi6.yaml
2023-03-05 05:55:29,559 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  # CAME
  REL_CLASS_NUM_LST: [ ]
  OBJ_CLASS_NUM_LST: [ ]
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 602                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 0             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_BGFG_RATIO: 3
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 31                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    ## CAME, 2022
    NUM_EXPERTS: 2
    USE_RELATION_AWARE_GATING: False
    USE_PER_CLASS_CONTEXT_AWARE: False
    PER_CLASS_ALPHA: 1.0
    LOSS_OPTION: "CAME_LOSS"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1 # fro fgpl 0.3
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048
DATASETS:
  TRAIN: ("openimage_v6_train",)
  VAL: ("openimage_v6_val",)
  TEST: ("openimage_v6_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5
  CUSTUM_EVAL: False       # eval SGDet model on custum images, output a json
  CUSTUM_PATH: '.'         # the folder that contains the custum images, only jpg files are allowed

2023-03-05 05:55:29,564 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  GQA_200_TEST: ()
  GQA_200_TRAIN: ()
  GQA_200_VAL: ()
  LOAD_PRECOMPUTE_DETECTION_BOX: False
  TEST: ('openimage_v6_test',)
  TRAIN: ('openimage_v6_train',)
  VAL: ('openimage_v6_val',)
  VG_TEST: ()
  VG_TRAIN: ()
  VG_VAL: ()
DETECTED_SGG_DIR: .
DTYPE: float16
GLOBAL_SETTING:
  BASIC_ENCODER: Hybrid-Attention
  CHOOSE_BEST_MODEL_BY_METRIC: _mean_recall
  DATASET_CHOICE: VG
  GCL_SETTING:
    GROUP_SPLIT_MODE: divide4
    KNOWLEDGE_LOSS_COEFFICIENT: 1.0
    KNOWLEDGE_TRANSFER_MODE: KL_logit_TopDown
    NO_RELATION_PENALTY: 0.1
    NO_RELATION_RESTRAIN: True
    ZERO_LABEL_PADDING_MODE: rand_insert
  PRINT_INTERVAL: 100
  RELATION_PREDICTOR: TransLike_GCL
  USE_BIAS: True
GLOVE_DIR: datasets/vg/glove
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  OBJ_CLASS_NUM_LST: []
  PRETRAINED_DETECTOR_CKPT: datasets/vg/detector_model/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  REL_CLASS_NUM_LST: []
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 0
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    GQA_200_NUM_CLASSES: 201
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 602
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
    VG_NUM_CLASSES: 151
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: none
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    DATA_RESAMPLING: False
    DATA_RESAMPLING_METHOD: bilvl
    DATA_RESAMPLING_PARAM:
      INSTANCE_DROP_RATE: 0.4
      REPEAT_DICT_DIR: 
      REPEAT_FACTOR: 0.012
    EMBED_DIM: 200
    EXPERT_VOTING: False
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    GQA_200_NUM_CLASSES: 101
    LABEL_SMOOTHING_LOSS: False
    LONGTAIL_PART_DICT: ['None', 'h', 't', 't', 'b', 'b', 'h', 'b', 'h', 'b', 'b', 'b', 't', 'b', 'b', 't', 'b', 't', 't', 'b', 'h', 'h', 'h', 'h', 'b', 'b', 't', 't', 't', 'h', 'h', 'h', 't', 'b', 't', 'b', 't', 't', 'h', 't', 'h', 'h', 't', 'h', 'b', 't', 'b', 'b', 'h', 'h', 'h']
    LOSS_OPTION: CROSS_ENTROPY_LOSS
    NUM_CLASSES: 31
    NUM_EXPERTS: 1
    NUM_SAMPLE_PER_GT_REL: 4
    PER_CLASS_ALPHA: 1.0
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: CausalAnalysisPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    RELATION_SAMPLING: False
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REPEAT_FACTOR: 0.02
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: False
    USE_GT_OBJECT_LABEL: False
    USE_PER_CLASS_CONTEXT_AWARE: False
    USE_RELATION_AWARE_GATING: False
    VG_NUM_CLASSES: 51
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: ./output/relation_baseline
PATHS_CATALOG: /lintianlin_group_v100/lgzhou/scene_graph_generation/came/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /lintianlin_group_v100/lgzhou/scene_graph_generation/came/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 16
  MAX_ITER: 40000
  MOMENTUM: 0.9
  PRE_VAL: False
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  CUSTUM_EVAL: False
  CUSTUM_PATH: .
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 8
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2023-03-05 05:55:29,569 maskrcnn_benchmark INFO: Saving config into: ./output/relation_baseline/config.yml
2023-03-05 05:55:29,606 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-05 05:55:29,606 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2023-03-05 05:55:29,607 maskrcnn_benchmark.data.build INFO: Loading data statistics from: ./output/relation_baseline/openimage_v6_train_statistics.cache
2023-03-05 05:55:29,607 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-05 05:55:55,484 maskrcnn_benchmark.data.build INFO: finish
2023-03-05 05:55:55,484 maskrcnn_benchmark.data.build INFO: Save data statistics to: ./output/relation_baseline/openimage_v6_train_statistics.cache
2023-03-05 05:55:55,484 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-05 05:55:56,186 maskrcnn_benchmark INFO: #################### prepare training ####################
2023-03-05 05:56:00,959 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-05 05:56:00,959 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2023-03-05 05:56:00,961 maskrcnn_benchmark.data.build INFO: Loading data statistics from: ./output/relation_baseline/openimage_v6_train_statistics.cache
2023-03-05 05:56:00,962 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-05 05:56:26,474 maskrcnn_benchmark.data.build INFO: finish
2023-03-05 05:56:26,475 maskrcnn_benchmark.data.build INFO: Save data statistics to: ./output/relation_baseline/openimage_v6_train_statistics.cache
2023-03-05 05:56:26,475 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-05 05:56:35,836 maskrcnn_benchmark INFO: #################### end model construction ####################
2023-03-05 05:56:37,223 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2023-03-05 05:56:37,230 maskrcnn_benchmark INFO: #################### end distributed ####################
2023-03-05 05:56:37,233 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from datasets/vg/detector_model/pretrained_faster_rcnn/model_final.pth
2023-03-05 06:03:46,221 maskrcnn_benchmark INFO: Using 1 GPUs
2023-03-05 06:03:46,221 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_rel_ovi6.yaml', distributed=False, local_rank=0, loss_option='CROSS_ENTROPY_LOSS', num_experts=1, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'False', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'False', 'MODEL.ROI_RELATION_HEAD.USE_RELATION_AWARE_GATING', 'False', 'MODEL.ROI_RELATION_HEAD.USE_PER_CLASS_CONTEXT_AWARE', 'False'], skip_test=False)
2023-03-05 06:03:46,221 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2023-03-05 06:03:48,166 maskrcnn_benchmark INFO: 
PyTorch version: 1.6.0+cu101
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 18.04.3 LTS
GCC version: (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0
CMake version: version 3.10.2

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 10.1.243
GPU models and configuration: GPU 0: Tesla V100-SXM2-32GB
Nvidia driver version: 418.67
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.17.3
[pip3] torch==1.6.0+cu101
[pip3] torch-tb-profiler==0.2.1
[pip3] torchaudio==0.8.1
[pip3] torchfile==0.1.0
[pip3] torchvision==0.7.0+cu101
[conda] Could not collect
        Pillow (6.2.1)
2023-03-05 06:03:48,166 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_rel_ovi6.yaml
2023-03-05 06:03:48,167 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  # CAME
  REL_CLASS_NUM_LST: [ ]
  OBJ_CLASS_NUM_LST: [ ]
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 602                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 0             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_BGFG_RATIO: 3
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 31                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    ## CAME, 2022
    NUM_EXPERTS: 2
    USE_RELATION_AWARE_GATING: False
    USE_PER_CLASS_CONTEXT_AWARE: False
    PER_CLASS_ALPHA: 1.0
    LOSS_OPTION: "CAME_LOSS"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1 # fro fgpl 0.3
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048
DATASETS:
  TRAIN: ("openimage_v6_train",)
  VAL: ("openimage_v6_val",)
  TEST: ("openimage_v6_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5
  CUSTUM_EVAL: False       # eval SGDet model on custum images, output a json
  CUSTUM_PATH: '.'         # the folder that contains the custum images, only jpg files are allowed

2023-03-05 06:03:48,169 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  GQA_200_TEST: ()
  GQA_200_TRAIN: ()
  GQA_200_VAL: ()
  LOAD_PRECOMPUTE_DETECTION_BOX: False
  TEST: ('openimage_v6_test',)
  TRAIN: ('openimage_v6_train',)
  VAL: ('openimage_v6_val',)
  VG_TEST: ()
  VG_TRAIN: ()
  VG_VAL: ()
DETECTED_SGG_DIR: .
DTYPE: float16
GLOBAL_SETTING:
  BASIC_ENCODER: Hybrid-Attention
  CHOOSE_BEST_MODEL_BY_METRIC: _mean_recall
  DATASET_CHOICE: VG
  GCL_SETTING:
    GROUP_SPLIT_MODE: divide4
    KNOWLEDGE_LOSS_COEFFICIENT: 1.0
    KNOWLEDGE_TRANSFER_MODE: KL_logit_TopDown
    NO_RELATION_PENALTY: 0.1
    NO_RELATION_RESTRAIN: True
    ZERO_LABEL_PADDING_MODE: rand_insert
  PRINT_INTERVAL: 100
  RELATION_PREDICTOR: TransLike_GCL
  USE_BIAS: True
GLOVE_DIR: datasets/vg/glove
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  OBJ_CLASS_NUM_LST: []
  PRETRAINED_DETECTOR_CKPT: ../bgnn/checkpoints/pretrained_detector/oiv6_det.pth
  RELATION_ON: True
  REL_CLASS_NUM_LST: []
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 0
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    GQA_200_NUM_CLASSES: 201
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 602
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
    VG_NUM_CLASSES: 151
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: none
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    DATA_RESAMPLING: False
    DATA_RESAMPLING_METHOD: bilvl
    DATA_RESAMPLING_PARAM:
      INSTANCE_DROP_RATE: 0.4
      REPEAT_DICT_DIR: 
      REPEAT_FACTOR: 0.012
    EMBED_DIM: 200
    EXPERT_VOTING: False
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    GQA_200_NUM_CLASSES: 101
    LABEL_SMOOTHING_LOSS: False
    LONGTAIL_PART_DICT: ['None', 'h', 't', 't', 'b', 'b', 'h', 'b', 'h', 'b', 'b', 'b', 't', 'b', 'b', 't', 'b', 't', 't', 'b', 'h', 'h', 'h', 'h', 'b', 'b', 't', 't', 't', 'h', 'h', 'h', 't', 'b', 't', 'b', 't', 't', 'h', 't', 'h', 'h', 't', 'h', 'b', 't', 'b', 'b', 'h', 'h', 'h']
    LOSS_OPTION: CROSS_ENTROPY_LOSS
    NUM_CLASSES: 31
    NUM_EXPERTS: 1
    NUM_SAMPLE_PER_GT_REL: 4
    PER_CLASS_ALPHA: 1.0
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: CausalAnalysisPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    RELATION_SAMPLING: False
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REPEAT_FACTOR: 0.02
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: False
    USE_GT_OBJECT_LABEL: False
    USE_PER_CLASS_CONTEXT_AWARE: False
    USE_RELATION_AWARE_GATING: False
    VG_NUM_CLASSES: 51
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: ./output/relation_baseline
PATHS_CATALOG: /lintianlin_group_v100/lgzhou/scene_graph_generation/came/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /lintianlin_group_v100/lgzhou/scene_graph_generation/came/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 16
  MAX_ITER: 40000
  MOMENTUM: 0.9
  PRE_VAL: False
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  CUSTUM_EVAL: False
  CUSTUM_PATH: .
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 8
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2023-03-05 06:03:48,172 maskrcnn_benchmark INFO: Saving config into: ./output/relation_baseline/config.yml
2023-03-05 06:03:48,199 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-05 06:03:48,199 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2023-03-05 06:03:48,201 maskrcnn_benchmark.data.build INFO: Loading data statistics from: ./output/relation_baseline/openimage_v6_train_statistics.cache
2023-03-05 06:03:48,201 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-05 06:04:15,232 maskrcnn_benchmark.data.build INFO: finish
2023-03-05 06:04:15,233 maskrcnn_benchmark.data.build INFO: Save data statistics to: ./output/relation_baseline/openimage_v6_train_statistics.cache
2023-03-05 06:04:15,233 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-05 06:04:15,912 maskrcnn_benchmark INFO: #################### prepare training ####################
2023-03-05 06:04:20,618 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-05 06:04:20,618 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2023-03-05 06:04:20,620 maskrcnn_benchmark.data.build INFO: Loading data statistics from: ./output/relation_baseline/openimage_v6_train_statistics.cache
2023-03-05 06:04:20,620 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-05 06:04:46,793 maskrcnn_benchmark.data.build INFO: finish
2023-03-05 06:04:46,794 maskrcnn_benchmark.data.build INFO: Save data statistics to: ./output/relation_baseline/openimage_v6_train_statistics.cache
2023-03-05 06:04:46,794 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2023-03-05 06:04:56,411 maskrcnn_benchmark INFO: #################### end model construction ####################
2023-03-05 06:04:57,536 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2023-03-05 06:04:57,544 maskrcnn_benchmark INFO: #################### end distributed ####################
2023-03-05 06:04:57,546 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from ../bgnn/checkpoints/pretrained_detector/oiv6_det.pth
2023-03-05 06:04:58,569 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.box_feature_extractor.fc6.bias in current model to roi_heads.box.feature_extractor.fc6.bias in loaded model.
2023-03-05 06:04:58,569 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.box_feature_extractor.fc6.weight in current model to roi_heads.box.feature_extractor.fc6.weight in loaded model.
2023-03-05 06:04:58,569 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.box_feature_extractor.fc7.bias in current model to roi_heads.box.feature_extractor.fc7.bias in loaded model.
2023-03-05 06:04:58,570 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.box_feature_extractor.fc7.weight in current model to roi_heads.box.feature_extractor.fc7.weight in loaded model.
2023-03-05 06:04:58,570 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias in current model to roi_heads.box.feature_extractor.fc6.bias in loaded model.
2023-03-05 06:04:58,570 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight in current model to roi_heads.box.feature_extractor.fc6.weight in loaded model.
2023-03-05 06:04:58,570 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias in current model to roi_heads.box.feature_extractor.fc7.bias in loaded model.
2023-03-05 06:04:58,570 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight in current model to roi_heads.box.feature_extractor.fc7.weight in loaded model.
2023-03-05 06:04:58,570 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias in current model to roi_heads.box.feature_extractor.pooler.reduce_channel.0.bias in loaded model.
2023-03-05 06:04:58,570 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight in current model to roi_heads.box.feature_extractor.pooler.reduce_channel.0.weight in loaded model.
2023-03-05 06:04:58,629 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! roi_heads.relation.box_feature_extractor.fc6.bias                                           loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)
2023-03-05 06:04:58,629 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! roi_heads.relation.box_feature_extractor.fc6.weight                                         loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)
2023-03-05 06:04:58,629 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! roi_heads.relation.box_feature_extractor.fc7.bias                                           loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)
2023-03-05 06:04:58,629 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! roi_heads.relation.box_feature_extractor.fc7.weight                                         loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)
2023-03-05 06:04:58,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.avg_post_ctx of shape (4096,)
2023-03-05 06:04:58,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias of shape (3072,)
2023-03-05 06:04:58,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight of shape (3072, 5136)
2023-03-05 06:04:58,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight of shape (603, 200)
2023-03-05 06:04:58,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias of shape (602,)
2023-03-05 06:04:58,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight of shape (602, 512)
2023-03-05 06:04:58,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias of shape (2560,)
2023-03-05 06:04:58,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight of shape (2560, 512)
2023-03-05 06:04:58,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0 of shape (2048,)
2023-03-05 06:04:58,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse of shape (2048,)
2023-03-05 06:04:58,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0 of shape (2048,)
2023-03-05 06:04:58,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse of shape (2048,)
2023-03-05 06:04:58,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0 of shape (2048, 512)
2023-03-05 06:04:58,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)
2023-03-05 06:04:58,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0 of shape (2048, 4808)
2023-03-05 06:04:58,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4808)
2023-03-05 06:04:58,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.lin_edge_h.bias of shape (512,)
2023-03-05 06:04:58,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.lin_edge_h.weight of shape (512, 1024)
2023-03-05 06:04:58,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.lin_obj_h.bias of shape (512,)
2023-03-05 06:04:58,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.lin_obj_h.weight of shape (512, 1024)
2023-03-05 06:04:58,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0 of shape (2048,)
2023-03-05 06:04:58,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse of shape (2048,)
2023-03-05 06:04:58,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0 of shape (2048,)
2023-03-05 06:04:58,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse of shape (2048,)
2023-03-05 06:04:58,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0 of shape (2048, 512)
2023-03-05 06:04:58,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)
2023-03-05 06:04:58,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0 of shape (2048, 4424)
2023-03-05 06:04:58,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4424)
2023-03-05 06:04:58,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.obj_embed1.weight of shape (602, 200)
2023-03-05 06:04:58,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.obj_embed2.weight of shape (602, 200)
2023-03-05 06:04:58,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pos_embed.0.bias of shape (32,)
2023-03-05 06:04:58,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pos_embed.0.weight of shape (32, 9)
2023-03-05 06:04:58,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pos_embed.1.bias of shape (32,)
2023-03-05 06:04:58,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pos_embed.1.num_batches_tracked of shape ()
2023-03-05 06:04:58,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pos_embed.1.running_mean of shape (32,)
2023-03-05 06:04:58,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pos_embed.1.running_var of shape (32,)
2023-03-05 06:04:58,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pos_embed.1.weight of shape (32,)
2023-03-05 06:04:58,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pos_embed.2.bias of shape (128,)
2023-03-05 06:04:58,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pos_embed.2.weight of shape (128, 32)
2023-03-05 06:04:58,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.untreated_dcd_feat of shape (4936,)
2023-03-05 06:04:58,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.untreated_edg_feat of shape (4296,)
2023-03-05 06:04:58,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.untreated_obj_feat of shape (4424,)
2023-03-05 06:04:58,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.ctx_compress.bias of shape (31,)
2023-03-05 06:04:58,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.ctx_compress.weight of shape (31, 4096)
2023-03-05 06:04:58,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.freq_bias.obj_baseline.weight of shape (362404, 31)
2023-03-05 06:04:58,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.post_cat.0.bias of shape (4096,)
2023-03-05 06:04:58,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.post_cat.0.weight of shape (4096, 1024)
2023-03-05 06:04:58,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.post_emb.bias of shape (1024,)
2023-03-05 06:04:58,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.post_emb.weight of shape (1024, 512)
2023-03-05 06:04:58,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.spt_emb.0.bias of shape (512,)
2023-03-05 06:04:58,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.spt_emb.0.weight of shape (512, 32)
2023-03-05 06:04:58,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.spt_emb.2.bias of shape (4096,)
2023-03-05 06:04:58,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.spt_emb.2.weight of shape (4096, 512)
2023-03-05 06:04:58,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.untreated_conv_spt of shape (4096,)
2023-03-05 06:04:58,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.untreated_feat of shape (4096,)
2023-03-05 06:04:58,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.untreated_spt of shape (32,)
2023-03-05 06:04:58,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.vis_compress.bias of shape (31,)
2023-03-05 06:04:58,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.vis_compress.weight of shape (31, 4096)
2023-03-05 06:04:58,632 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias                       loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)
2023-03-05 06:04:58,632 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight                     loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)
2023-03-05 06:04:58,632 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias                       loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)
2023-03-05 06:04:58,632 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight                     loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)
2023-03-05 06:04:58,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias of shape (256,)
2023-03-05 06:04:58,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight of shape (256, 1024, 3, 3)
2023-03-05 06:04:58,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.0.bias of shape (128,)
2023-03-05 06:04:58,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.0.weight of shape (128, 2, 7, 7)
2023-03-05 06:04:58,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.2.bias of shape (128,)
2023-03-05 06:04:58,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.2.num_batches_tracked of shape ()
2023-03-05 06:04:58,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.2.running_mean of shape (128,)
2023-03-05 06:04:58,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.2.running_var of shape (128,)
2023-03-05 06:04:58,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.2.weight of shape (128,)
2023-03-05 06:04:58,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.4.bias of shape (256,)
2023-03-05 06:04:58,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.4.weight of shape (256, 128, 3, 3)
2023-03-05 06:04:58,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.6.bias of shape (256,)
2023-03-05 06:04:58,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.6.num_batches_tracked of shape ()
2023-03-05 06:04:58,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.6.running_mean of shape (256,)
2023-03-05 06:04:58,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.6.running_var of shape (256,)
2023-03-05 06:04:58,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.6.weight of shape (256,)
2023-03-05 06:04:59,252 maskrcnn_benchmark INFO: #################### end load checkpointer ####################
2023-03-05 06:04:59,252 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2023-03-05 06:05:03,521 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into ./output/relation_baseline/labels.json
2023-03-05 06:05:03,665 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2023-03-05 06:05:03,714 maskrcnn_benchmark INFO: #################### end dataloader ####################
2023-03-05 06:05:03,714 maskrcnn_benchmark INFO: Start training
2023-03-05 06:05:11,753 maskrcnn_benchmark INFO: ---Total norm inf clip coef 0.00000-----------------
2023-03-05 06:05:11,771 maskrcnn_benchmark INFO: roi_heads.relation.predictor.ctx_compress.bias    : inf, (torch.Size([31]))
2023-03-05 06:05:11,771 maskrcnn_benchmark INFO: roi_heads.relation.predictor.vis_compress.weight  : inf, (torch.Size([31, 4096]))
2023-03-05 06:05:11,771 maskrcnn_benchmark INFO: roi_heads.relation.predictor.vis_compress.bias    : inf, (torch.Size([31]))
2023-03-05 06:05:11,772 maskrcnn_benchmark INFO: roi_heads.relation.predictor.spt_emb.2.weight     : 117272.35938, (torch.Size([4096, 512]))
2023-03-05 06:05:11,772 maskrcnn_benchmark INFO: roi_heads.relation.predictor.spt_emb.0.weight     : 36049.19141, (torch.Size([512, 32]))
2023-03-05 06:05:11,772 maskrcnn_benchmark INFO: roi_heads.relation.predictor.spt_emb.2.bias       : 31762.48633, (torch.Size([4096]))
2023-03-05 06:05:11,772 maskrcnn_benchmark INFO: roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 28168.80469, (torch.Size([362404, 31]))
2023-03-05 06:05:11,772 maskrcnn_benchmark INFO: roi_heads.relation.predictor.spt_emb.0.bias       : 9079.03516, (torch.Size([512]))
2023-03-05 06:05:11,772 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 39.75647, (torch.Size([4096, 4096]))
2023-03-05 06:05:11,772 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 33.65598, (torch.Size([4096, 12544]))
2023-03-05 06:05:11,772 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 8.13907, (torch.Size([256, 1024, 3, 3]))
2023-03-05 06:05:11,772 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 3.83038, (torch.Size([3072, 5136]))
2023-03-05 06:05:11,772 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 3.04401, (torch.Size([256, 128, 3, 3]))
2023-03-05 06:05:11,773 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc7.weight: 2.04204, (torch.Size([4096, 4096]))
2023-03-05 06:05:11,773 maskrcnn_benchmark INFO: roi_heads.relation.predictor.ctx_compress.weight  : 1.86829, (torch.Size([31, 4096]))
2023-03-05 06:05:11,773 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 1.74827, (torch.Size([512, 1024]))
2023-03-05 06:05:11,773 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_cat.0.weight    : 1.44975, (torch.Size([4096, 1024]))
2023-03-05 06:05:11,773 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 1.21412, (torch.Size([602, 512]))
2023-03-05 06:05:11,773 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc6.weight: 0.99201, (torch.Size([4096, 12544]))
2023-03-05 06:05:11,773 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.90959, (torch.Size([128, 2, 7, 7]))
2023-03-05 06:05:11,773 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.90809, (torch.Size([2048, 4808]))
2023-03-05 06:05:11,773 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.89953, (torch.Size([2048, 4808]))
2023-03-05 06:05:11,773 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.80351, (torch.Size([602]))
2023-03-05 06:05:11,774 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.47346, (torch.Size([512]))
2023-03-05 06:05:11,774 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.44570, (torch.Size([4096]))
2023-03-05 06:05:11,774 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.27675, (torch.Size([512, 1024]))
2023-03-05 06:05:11,774 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.26286, (torch.Size([3072]))
2023-03-05 06:05:11,774 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.20931, (torch.Size([256]))
2023-03-05 06:05:11,774 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.17291, (torch.Size([2048, 512]))
2023-03-05 06:05:11,774 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.16169, (torch.Size([2048, 512]))
2023-03-05 06:05:11,774 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.15586, (torch.Size([128]))
2023-03-05 06:05:11,774 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.14786, (torch.Size([2560, 512]))
2023-03-05 06:05:11,774 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.14591, (torch.Size([2048, 4424]))
2023-03-05 06:05:11,774 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.14496, (torch.Size([2048, 4424]))
2023-03-05 06:05:11,775 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.13678, (torch.Size([4096]))
2023-03-05 06:05:11,775 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.11159, (torch.Size([256]))
2023-03-05 06:05:11,775 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.10791, (torch.Size([2560]))
2023-03-05 06:05:11,775 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.07120, (torch.Size([512]))
2023-03-05 06:05:11,775 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.07113, (torch.Size([2048]))
2023-03-05 06:05:11,775 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.07113, (torch.Size([2048]))
2023-03-05 06:05:11,775 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_emb.weight      : 0.06895, (torch.Size([1024, 512]))
2023-03-05 06:05:11,775 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_cat.0.bias      : 0.06873, (torch.Size([4096]))
2023-03-05 06:05:11,775 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.06826, (torch.Size([2048]))
2023-03-05 06:05:11,775 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.06826, (torch.Size([2048]))
2023-03-05 06:05:11,775 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.06263, (torch.Size([128]))
2023-03-05 06:05:11,776 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.04944, (torch.Size([256]))
2023-03-05 06:05:11,776 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc7.bias : 0.04941, (torch.Size([4096]))
2023-03-05 06:05:11,776 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.04772, (torch.Size([256]))
2023-03-05 06:05:11,776 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_emb.bias        : 0.04570, (torch.Size([1024]))
2023-03-05 06:05:11,776 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.03803, (torch.Size([128]))
2023-03-05 06:05:11,776 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.02938, (torch.Size([128, 32]))
2023-03-05 06:05:11,776 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.02902, (torch.Size([2048, 512]))
2023-03-05 06:05:11,776 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.02555, (torch.Size([2048, 512]))
2023-03-05 06:05:11,776 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.01958, (torch.Size([602, 200]))
2023-03-05 06:05:11,776 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.01416, (torch.Size([32, 9]))
2023-03-05 06:05:11,777 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01247, (torch.Size([602, 200]))
2023-03-05 06:05:11,777 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.01074, (torch.Size([128]))
2023-03-05 06:05:11,777 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.01017, (torch.Size([2048]))
2023-03-05 06:05:11,777 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.01017, (torch.Size([2048]))
2023-03-05 06:05:11,777 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.01013, (torch.Size([2048]))
2023-03-05 06:05:11,777 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.01013, (torch.Size([2048]))
2023-03-05 06:05:11,777 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc6.bias : 0.00784, (torch.Size([4096]))
2023-03-05 06:05:11,777 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00700, (torch.Size([32]))
2023-03-05 06:05:11,777 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.00487, (torch.Size([603, 200]))
2023-03-05 06:05:11,777 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00282, (torch.Size([32]))
2023-03-05 06:05:11,777 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2023-03-05 06:05:11,778 maskrcnn_benchmark INFO: -------------------------------
2023-03-05 06:21:17,380 maskrcnn_benchmark INFO: eta: 2 days, 5:49:19  iter: 200  loss: 3.7896 (5.1035)  loss_rel: 0.3938 (0.4950)  loss_refine_obj: 0.5073 (1.0662)  auxiliary_ctx: 0.3465 (0.5994)  auxiliary_vis: 0.5808 (0.6853)  auxiliary_frq: 1.9407 (2.2576)  time: 4.8361 (4.8683)  data: 0.0281 (0.1955)  lr: 0.073312  max mem: 7738
